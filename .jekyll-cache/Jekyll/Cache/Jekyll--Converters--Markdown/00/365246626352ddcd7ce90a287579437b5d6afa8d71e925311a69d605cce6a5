I"<p>Goal of Artificial General Intelligence (AGI): <br />
Build general-purpose Super-Intelligences</p>

<p>HOW??? <br />
‚Äì&gt; Build system by trail &amp; error (Artificial Approach) <br />
‚Äì&gt; Mimic human behavior (Natural Approach) (Not covered in this course)</p>

<p>So we need THEORIES to guide us.</p>

<p>For Artificial Approach:</p>
<ul>
  <li>AI system includes:
    <ul>
      <li>Logic/language based</li>
      <li>Economics inspired</li>
      <li>Cybernetics</li>
      <li>Machine Learning</li>
      <li>Information processing</li>
    </ul>
  </li>
</ul>

<hr />
<p><br />
Intelligence does not have a formal definition yet.</p>
<pre>
Humanly Thinking:	Cognitive Science
Humanly Acting:		Turing test, Behaviorism
Rationally Thinking:	Laws Thought
Rationally Acting:	Doing the Right Thing (the topic we discuss)
</pre>

<p><strong>Decision Theory = Probability + Utility Theory</strong><br />
Uncertain world, environmental probability distribution is <em>known</em>.</p>

<p><strong>Universal Induction = Ockham + Bayes + Turing</strong><br />
Sequence prediction for <em>unknown</em> prior distribution.</p>

<p><strong>AI = Decision Theory + Universal Induction</strong></p>

<hr />
<p><br />
UAI covers all Reinforcement Learning(RL) problem types<br />
‚Äì&gt; Statistical Machine Learning:<br />
Mostly independent and identically distributed(i.i.d.) data classification, regression, clustering<br />
‚Äì&gt; RL Problems &amp; Algorithms:<br />
Stochastic, unknown, non-i.i.d. environments<br />
‚Äì&gt; Artificial Intelligence:<br />
Traditionally deterministic, known world/planning problem</p>

<hr />
<p><br />
Informal Definition of Intelligence:<br />
Intelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.</p>

<p>Induting a model of the environment ‚Äì&gt; Make predictions ‚Äì&gt; Make a decision ‚Äì&gt; Do the next action</p>

<h2 id="induction">Induction:</h2>
<p><strong>Occam‚Äôs razor</strong>: Take simplest hypothesis consistent with data.</p>

<p>Then how to quantify ‚Äúsimplicity‚Äù?<br />
Description Length!</p>

<p>‚Äì&gt; Shortest description of object is best explanation.</p>

<p>Shortest description = Shortest prgram for a string on a Turing Machines T ‚Äì&gt; Best extrapolation = Prediction</p>

\[K_T(x) = \min_{p}\{\ell(p) : T(p) = x\}\]

<p><strong>Kolmogorov-complexity(x):</strong><br />
\(K(x) = K_U(x) \leq K_T(x) + c_T\)</p>

<p>However, K(x) is uncomputable and p can not be easily found.</p>

<p>So we need to have prior for each possible p. That is why we introduce Bayes‚Äô rule here.</p>

<p><strong>Bayes‚Äô rule:</strong><br />
\(P(H_i | D) = \cfrac{P(D|H_i) \cdot P(H_i)}{\sum_{i}P(D|H_i) \cdot P(H_i)}\)</p>

<p>$P(H_i)$ is prior probability.<br />
$P(H_i|D)$ is posterior probability.</p>

<p>$P(D | H_i)$ is easy to describe.<br />
But we do not know how to choose $P(H_i)$.</p>

<p><strong>Epicurus</strong>: If more than one theory is consistent with the observations, keep all theories.<br />
So we refine Occam‚Äôs razor with Kolmogorov complexity:
\(P(H_i) := 2^{-K_{T/U}(H_i)}\)</p>

<p>But if we use T, we do not know how to choose T.<br />
If we use U, it is incomputable.</p>

<p><strong>Solomonoff</strong> combined Occam, Epicurus, Bayes and Turing. ‚Äì&gt; Theory of sequential prediction</p>

<p>$M(x)$ = P(UTM outputs x when input is random)<br />
$M(y|x) = M(xy)/M(x)$</p>

<p><strong>The Minimum Description Length Principle</strong><br />
$y$ of highest $M(y|x)$ = $y$ of smallest $K_T(xy)$.</p>

<p>$x$ similar to $y$ ‚Äì&gt; $K(x|y) := \min \{\ell(p) : U(p,y) = x\}$</p>
:ET